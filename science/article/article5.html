
<!DOCTYPE html>
<html lang="ru">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Разработка комбинированного подхода к обучению моделей исправления программ на основе синтетических и реальных данных - Синяева Элеонора Витальевна</title>
    <link rel="stylesheet" href="../../css/master_style.css">
    <link rel="stylesheet" href="../../css/article.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/tsparticles@1.39.0/tsparticles.min.js"></script>
</head>

<body>

    <div id="tsparticles" style="position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: -1;"></div>

    <!-- Верхний блок -->
    <div class="top-block">
        <div class="lang-box">
            <!-- <a href="article5_eng.html" class="lang-link">EN</a> -->
        </div>
        <div class="university-links">
            <a href="http://donntu.ru" target="_blank">ДонНТУ</a>
            <a href="http://masters.donntu.ru" target="_blank" title="Перейти на портал магистров ДонНТУ">Портал
                магистров</a>
        </div>
    </div>

    <!-- Основное содержимое -->
    <div class="container">
        <div class="article-container">
            <div class="article-content">
                <div class="udk">УДК 004.8</div>

                <div class="article-header">
                    <div class="article-title">
                        РАЗРАБОТКА КОМБИНИРОВАННОГО ПОДХОДА К ОБУЧЕНИЮ МОДЕЛЕЙ ИСПРАВЛЕНИЯ ПРОГРАММ НА ОСНОВЕ СИНТЕТИЧЕСКИХ И РЕАЛЬНЫХ ДАННЫХ
                    </div>

                    <div class="authors">
                        Боднар А.В.<sup>1</sup>, Синяева Э.В.<sup>2</sup>
                    </div>

                    <div class="university">
                        ФГБОУ ВО «Донецкий национальный технический университет»
                    </div>

                    <div class="contact">
                        <sup>1</sup> к.т.н, доцент, e-mail: linabykova13@ya.ru<br>
                        <sup>2</sup> магистрант, e-mail: elli200314@gmail.com
                    </div>

                    <div class="abstract">
                        <p><strong>Боднар А.В., Синяева Э.В. Разработка комбинированного подхода к обучению моделей исправления программ на основе синтетических и реальных данных.</strong> В работе рассматривается метод генерации синтетических программ для обучения моделей автоматического исправления кода. Предложен синтаксический генератор программ, основанный на представлении исходного кода в виде последовательностей правил грамматики и использовании рекуррентной сети LSTM. Подход обеспечивает создание синтаксически корректных и компилируемых программ, близких по структуре к реальным. Синтетические данные объединяются с исходным набором и применяются для обучения моделей локализации и исправления ошибок. Проведены эксперименты с моделями DrRepair и TransRepair, подтвердившие повышение точности исправления программ за счёт расширения обучающих данных.</p>
                        <p class="keywords">
                            <strong>Ключевые слова:</strong> генерация программ, синтетические данные, исправление кода, нейросетевые модели, машинное обучение.
                        </p>

                        <p><strong>Bodnar A.V., Sinyaeva E.V. Development of a combined approach to training program correction models based on synthetic and real data.</strong> The paper examines a method for generating synthetic programs for training automatic code correction models. A syntactic program generator is proposed based on representing source code as sequences of grammar rules and using an LSTM recurrent network. This approach enables the creation of syntactically correct and compilable programs with a structure similar to real programs. Synthetic data is combined with the original dataset and used to train error localization and correction models. Experiments with the DrRepair and TransRepair models were conducted, confirming an increase in program correction accuracy due to the expansion of training data.</p>
                        <p class="keywords">
                            <strong>Keywords:</strong> program generation, synthetic data, code correction, neural network models, machine learning.
                        </p>
                    </div>

                    <div class="section">
                        <div class="section-title">Введение</div>
                        <p>Синтаксические ошибки представляют собой проблему как для начинающих программистов, так и для кода. Новичкам часто не хватает знаний для преодоления этих препятствий, и они не могут понять сообщения об ошибках компилятора, в то время как код, предлагаемый компиляторами, также не застрахован от синтаксических ошибок. Методы автоматического исправления программ направлены на решение этих проблем путём автоматического исправления синтаксических ошибок и предоставления обратной связи. Эти методы приносят пользу как начинающим программистам, так и системам искусственного интеллекта, повышая качество и надёжность кода.</p>
                        <p>В недавних исследованиях изучались различные методы глубокого обучения для автоматизированного исправления программ. Однако большинство работ сосредоточены на внедрении различных синтаксических ошибок в ограниченный набор корректных программ для обучения, главным образом из-за нехватки общедоступных наборов данных, специально разработанных для исправления синтаксических ошибок. В отличие от этого подхода, рассматриваем задачу расширения небольших и ограниченных наборов данных путём синтеза новых программ, что способствует развитию автоматического исправления программ.</p>
                        <p>Хотя современные языковые модели демонстрируют исключительную производительность при решении различных задач, предлагается два усовершенствования для повышения эффективности существующих моделей и достижения сопоставимых результатов при меньших требованиях к ресурсам. Подход включает разделение исходного набора обучающих данных на части и создание на их основе синтетических программ. Комбинация исходных и синтетических данных используется для обучения корректоров кода, которые затем агрегируются для генерации исправлений кода и устранения синтаксических ошибок.</p>
                    </div>

                    <div class="section">
                        <div class="section-title">Архитектура предлагаемой модели генерации исправлений кода</div>
                        <p>Генератор кода на основе синтаксиса решает задачу обучения на синтетических данных, стремясь генерировать не только синтаксически правильные программы, но и программы, похожие на те, что создают люди, изучающие программирование. Этот аспект имеет решающее значение для того, чтобы модель глубокого обучения могла эффективно обслуживать предполагаемых пользователей.</p>
                        <p>Для этого предложен метод генерации синтаксически правильных программ с использованием заданного начального набора данных. Чтобы повысить синтаксическую корректность синтетического кода, программы представляются в виде последовательности правил грамматики в процессе генерации. Например, исходный код «i = i + 1» представлен как последовательность грамматических правил, полученных в результате обхода дерева синтаксического разбора в глубину. Для генерации кода используется структура кодер-декодер. Выбор правил синтаксиса для каждого шага зависит от входных переменных и результатов предыдущих генераций. Этот процесс принятия решений обучается на предоставленном наборе данных.</p>
                        <div class="figure">
                            <img src="../../img/Статья 5 Рисунок 1.png" alt="Архитектура предлагаемой модели" style="max-width: 80%;">
                            <div class="figure-caption">Рисунок 1 – Архитектура предлагаемой модели</div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">Модель локализации ошибок</div>
                        <p>Хотя корректоры продемонстрировали эффективность в прогнозировании местоположения ошибок программирования, наблюдаются потенциальные преимущества использования альтернативных методов, основанных на необработанном коде или сообщениях компилятора. Основываясь на этом подходе, учитывается расположение операторов объявлений, которое является надежным и легко идентифицируемым источником для локализации ошибок. Это подчеркивает преимущества рассмотрения альтернативных источников информации для повышения точности методов локализации ошибок.</p>
                        
                        <div class="section">
                            <div class="section-title">Постановка задачи</div>
                            <p>В задаче восстановления программы, если задана программа с L строками кода x=(x₁,...,xₗ), которая не проходит компиляцию, цель состоит в том, чтобы найти ошибочную строку L и предложить исправление xr, которое приведет к успешной компиляции или снизит серьёзность сообщений об ошибках. Этот итерационный процесс продолжается до тех пор, пока исправленная программа не будет успешно скомпилирована или не будет достигнуто максимально допустимое количество попыток восстановления.</p>
                            <p>Генератор кода на основе синтаксиса (SCG) использует существующий набор данных для генерации аналогичных программ. Исходные и синтетические наборы данных объединяются и используются в качестве обучающих данных для модели корректора, которая анализирует программы с ошибками и генерирует соответствующие исправления.</p>
                            <p>На этапе вывода прогнозы нескольких независимых моделей корректора и локализации ошибок агрегируются с использованием методов ансамблевого обучения для повышения общей производительности. Предлагаемый подход принимает только исправления, которые успешно проходят тесты компилятора как надёжные решения.</p>
                        </div>

                        <p>Выбор подходящего представления является важным начальным шагом в разработке генератора кода. Варианты включают n-граммы, последовательности токенов, абстрактные синтаксические деревья (AST) и другие. Последовательностные представления часто генерируют синтаксически некорректные программы. Чтобы устранить это ограничение, в подход включены синтаксические правила. Используется сериализованное представление на основе AST. Код изначально анализируется в AST на основе предопределенного набора грамматических правил.</p>
                        
                        <div class="figure">
                            <img src="../../img/Статья 5 Рисунок 2.png" alt="Конвейер синтаксического генератора кода" style="max-width: 90%;">
                            <div class="figure-caption">Рисунок 2 – Конвейер синтаксического генератора кода</div>
                        </div>

                        <p>После разбора AST числовая последовательность генерируется путем обхода дерева в глубину с учетом соответствующих правил грамматики. Например, фрагмент кода «i = i + 1» преобразуется в числовую последовательность «4 1 2 4 1 2 5 6». Каждое число в последовательности представляет собой правило грамматики, используемое на соответствующем этапе обхода AST. Для упрощения процесса генерации поддерживается стек действий, который отслеживает текущее состояние генерации. Выбранные правила помещаются в стек, а начальный нетерминальный символ удаляется во время генерации. Этот процесс продолжается до тех пор, пока стек не опустеет. В реализации используется 493 различных правила грамматики языка C.</p>
                    </div>

                    <div class="section">
                        <div class="section-title">Генеративная модель</div>
                        <p>Синтаксический подход к генерации синтетического кода позволяет создавать синтаксически правильные программы, но приводит к более длинным последовательностям представлений. Для решения этой проблемы программа делится на несколько частей на основе правил разбора. Корневой узел AST и поддеревья его листовых узлов сериализуются и используются для обучения. Для обучения генеративной модели используется двухслойная сеть LSTM. Модель получает предыдущее действие и родительское действие и предсказывает следующее действие. Родительское действие относится к действию родительского узла в дереве анализа относительно текущего узла. Такое включение позволяет модели получать дополнительные структурные знания.</p>
                        
                        <p>Каждый шаг генерируется на основе изученного распределения из начального набора данных и предопределенных правил грамматики, что гарантирует выбор только грамматически правильных правил. Опишем алгоритм построения синтетического кода из набора операторов.</p>

                        <p><strong>Входные данные:</strong></p>
                        <ul>
                            <li>N – количество генерируемых операторов (строк кода, выражений или инструкций);</li>
                            <li>S – множество доступных операторов;</li>
                        </ul>

                        <p><strong>Пошаговое описание:</strong></p>
                        <ol>
                            <li><strong>Цикл генерации операторов</strong> – для каждого шага i создаётся кодовый фрагмент (Ci) и множество переменных Vi. Итоговая программа (C) и множество переменных (V) постепенно пополняются.</li>
                            <li><strong>Проверка конфликтов переменных</strong> – для каждой переменной проверяется, не пересекается ли она по имени с другой переменной. При наличии конфликта выполняется переименование.</li>
                            <li><strong>Инициализация всех переменных</strong> – создаются начальные значения всех переменных для обеспечения корректности программы.</li>
                            <li><strong>Объединение инициализации и основного кода</strong> – объединяется часть инициализации и сгенерированный код.</li>
                            <li><strong>Проверка компиляции</strong> – финальная проверка, что программа успешно компилируется.</li>
                        </ol>

                        <p>Генеративная модель создаёт короткие фрагменты кода, которые отличаются от реальных программ по длине и разнообразию символов. Для генерации более длинных программ используется стратегия объединения нескольких сгенерированных фрагментов кода. Количество операторов, определённых пользователями, обозначается как N. Эти операторы генерируются с использованием генеративной модели, что приводит к набору доступных операторов S. При генерации инициализирующей части программы фокусируется внимание на объявлении переменных без присвоения им значений, так как присвоение не влияет на компиляцию. Следуя алгоритму генерации, удаётся создавать компилируемые программы, демонстрирующие сходство с заданными, что устраняет разрыв между синтетическим и реальным кодом.</p>
                    </div>

                    <div class="section">
                        <div class="section-title">Экспериментальная установка</div>
                        <p>Для проверки эффективности проводятся эксперименты с использованием моделей DrRepair и TransRepair. DrRepair – двухэтапная модель: сначала предсказывает некорректную строку, затем предлагает исправления. TransRepair – модель на основе преобразователя, учитывающая контекст каждой строки кода и сообщения об ошибках для предсказания ошибок и исправлений. Используется набор программ DeepFix, включающий более 40000 программ на языке C. Программы делятся на 5 частей для проведения перекрёстной проверки. Для тестирования размер пучка составляет 100, максимальное число попыток исправления – 5. Также для проверки используется набор однострочных программ с ошибками из Tracer.</p>

                        <div class="section">
                            <div class="section-title">Гиперпараметры и детали обучения</div>
                            <p>Синтетическая генерация кода использует двухслойную LSTM с коэффициентом отсева 0,5. Размерность вложений – 128, скрытых состояний – 512. Модель локализации ошибок – двухслойная архитектура преобразователя с теми же параметрами. Оптимизация осуществляется с помощью Adam, размер пакета – 128, скорость обучения – 0,001.</p>
                            <p>Для обучения моделей генерируются около 8 000 программ на каждый раздел, 40% добавляются в обучающий набор DrRepair, ещё 40% – в TransRepair. С помощью метода повреждения программ создаётся более 1 300 000 ошибочных программ на языке C.</p>
                        </div>

                        <div class="section">
                            <div class="section-title">Базовые показатели</div>
                            <p>Производительность сравнивается с моделями DeepFix, RLAssist, SampleFix, DrRepair, BIFI, MultiFix, PaLM и TransRepair. Точность определяется как отношение числа исправленных программ к общему числу ошибочных программ. Исправленные программы – это те, которые успешно компилируются без сообщений об ошибках.</p>
                            <div class="figure">
                                <img src="../../img/Статья 5 Рисунок 3.png" alt="Пример работы модели" style="max-width: 70%;">
                                <div class="figure-caption">Рисунок 3 – Пример работы модели</div>
                            </div>
                        </div>
                    </div>

                    <div class="section">
                        <div class="section-title">Заключение</div>
                        <p>В статье проведён анализ эффективности комбинированного подхода к обучению моделей автоматического исправления программ, основанного на интеграции синтетических и реальных данных. Предложен синтаксический генератор программ, использующий представление исходного кода в виде последовательностей правил грамматики и рекуррентную сеть LSTM, что позволяет создавать синтаксически корректные и компилируемые фрагменты кода, структурно приближённые к реальным программам, написанным обучающимися.</p>
                        <p>Эксперименты с моделями DrRepair и TransRepair на наборе данных DeepFix показали, что расширение обучающей выборки за счёт синтетически сгенерированных программ приводит к повышению точности локализации и исправления синтаксических ошибок. Предложенный подход позволяет частично преодолеть проблему дефицита размеченных данных для задачи автоматического исправления кода и демонстрирует перспективность использования синтетических данных в обучении нейросетевых моделей программного исправления.</p>
                        <p>В дальнейшем планируется исследовать применимость метода к другим языкам программирования и его интеграцию с современными архитектурами на основе трансформеров. Также представляется перспективным исследование комбинирования различных типов синтетических данных и разработка адаптивных методов генерации, учитывающих специфику конкретных доменов программирования.</p>
                    </div>

                    <div class="references">
                        <div class="section-title">Литература</div>
                        <div class="reference-list">
                            <div class="reference-item">1. Потоцкий С. А., Кузнецов А. В. Автоматическое исправление программ с использованием глубоких нейронных сетей // Программирование. – 2022. – Т. 48. – № 3. – С. 215–229.</div>
                            <div class="reference-item">2. Gupta R., Pal S., Kanade A., Shevade S. DeepFix: Fixing Common C Language Errors by Deep Learning // Proceedings of the AAAI Conference on Artificial Intelligence. – 2017. – Vol. 31. – P. 1345–1351.</div>
                            <div class="reference-item">3. Yasunaga M., Liang P. DrRepair: JIT Learning for Automatic Program Repair // Advances in Neural Information Processing Systems (NeurIPS). – 2020. – Vol. 33. – P. 10382–10394.</div>
                            <div class="reference-item">4. Chen Z., Su Z. Guided Learning for Repairing Syntax Errors // ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA). – 2019. – P. 1081–1103.</div>
                            <div class="reference-item">5. Ahmed M., Rahman M. M., Roy C. K., Schneider K. SampleFix: Learning-based Automatic Program Repair // Empirical Software Engineering. – 2022. – Vol. 27. – Article 127.</div>
                            <div class="reference-item">6. Kim D., Nam J., Song J., Kim S. Automatic patch generation learned from human-written patches // Proceedings of the IEEE International Conference on Software Engineering (ICSE). – 2013. – P. 802–811.</div>
                            <div class="reference-item">7. Chen Q., Li Y., Chen B., et al. TransRepair: Transformer-Based Model for Program Repair // IEEE Transactions on Software Engineering. – 2023. – Vol. 49. – No. 2. – P. 760–774.</div>
                            <div class="reference-item">8. Le X. B. D., Chu D. H., Lo D., Le T. N. Q. Learning to Fix Build Errors with Graph Neural Networks // Proceedings of the International Conference on Software Maintenance and Evolution (ICSME). – 2021. – P. 122–133.</div>
                            <div class="reference-item">9. Long F., Rinard M. Automatic patch generation by learning correct code // ACM SIGPLAN Notices. – 2016. – Vol. 51. – No. 1. – P. 298–312.</div>
                            <div class="reference-item">10. Власов П. Е., Чижов К. Н. Генерация синтетических программ для обучения моделей анализа кода // Информационные технологии и вычислительные системы. – 2023. – № 4. – С. 41–55.</div>
                            <div class="reference-item">11. Vaswani A., Shazeer N., Parmar N., et al. Attention Is All You Need // Advances in Neural Information Processing Systems (NeurIPS). – 2017. – Vol. 30. – P. 5998–6008.</div>
                        </div>
                    </div>

                    <a href="../../science/index_ru.html" class="article-back-link">← Назад к научным трудам</a>
                </div>
            </div>
        </div>
    </div>

    <!-- Нижнее меню -->
    <footer class="footer-menu">
        <a class="footer-item" href="../../index_ru.html">Резюме</a>
        <a class="footer-item" href="../../diss/index_ru.html">Реферат</a>
        <a class="footer-item" href="../../science/index_ru.html">Научные труды</a>
        <a class="footer-item" href="../../ind/index_ru.html">Индивидуальный раздел</a>
    </footer>

    <script src="../../js/particles-config.js"></script>
    <script src="../../js/main.js"></script>
    <script src="../../js/script.js"></script>

</body>

</html>
